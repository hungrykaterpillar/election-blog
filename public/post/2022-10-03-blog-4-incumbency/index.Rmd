---
title: Blog 4 - Incumbency
author: ''
date: '2022-10-03'
slug: []
categories: []
tags: []
---
```{r setup, include = FALSE}
# read csv file and create an object, h
library(readr)
rs <- read_csv("data/2018_ratings_share_Rev.csv")
h <- read_csv("data/house party vote share by district 1948-2020.csv")

EE_data_R1 <- read_csv("data/Election_Economy_R1.csv")
HVS_data <- read_csv("data/house party vote share by district 1948-2020_R1.csv")
lm_incumb_D1 <- lm(DemVotes ~ incumbent_party+open_seat, data = HVS_data)

# loading required packages
library(tidyverse)
library(ggplot2)
library(sf)
library(usmap)
```

```{r include = FALSE}
D_2018 <- h %>%
  filter(raceYear == 2018) %>%
  select(raceYear, State, district_num, district_id, RepVotesMajorPercent, DemVotesMajorPercent) %>%
  group_by(district_num, State) %>%
  mutate(R_votemargin_cd = (RepVotesMajorPercent)-(DemVotesMajorPercent), D_votemargin_cd = (DemVotesMajorPercent)-(RepVotesMajorPercent), Rating = ifelse(DemVotesMajorPercent>56, 1, ifelse(DemVotesMajorPercent>54 & DemVotesMajorPercent<= 56, 2, ifelse(DemVotesMajorPercent>52 & DemVotesMajorPercent<= 54, 3, ifelse(DemVotesMajorPercent>= 48 & DemVotesMajorPercent<= 52, 4, ifelse(DemVotesMajorPercent >= 46 & DemVotesMajorPercent<48, 5, ifelse(DemVotesMajorPercent>= 44 & DemVotesMajorPercent<46, 6, ifelse(DemVotesMajorPercent<44,7))))))))%>%
  rename(DISTRICT = district_num, STATENAME = State)
```

```{r include = FALSE}
D_2018_RS <- rs %>%
  select(STATENAME, DISTRICT, cpr_num, inside_elections_num, crystal_ball_num, avg) %>%
  group_by(DISTRICT, STATENAME) %>%
  rename(DISTRICT = DISTRICT, STATENAME = STATENAME)

D_2018_Com <- D_2018 %>% left_join(D_2018_RS, by=c("DISTRICT", "STATENAME"))

D_2018_R_com <- D_2018_Com %>%
  select(STATENAME, DISTRICT, cpr_num, inside_elections_num, crystal_ball_num, avg, Rating) %>%
  group_by(DISTRICT, STATENAME) %>%
  mutate(Accuracy = (Rating)-(cpr_num))%>%
  rename(DISTRICT = DISTRICT, STATENAME = STATENAME)
```

```{r include = FALSE}
# load geographic data
get_congress_map <- function(cong=114) {
  tmp_file <- tempfile()
  tmp_dir <- tempdir()
  zp <- sprintf("https://cdmaps.polisci.ucla.edu/shp/districts114.zip",cong)
  download.file(zp, tmp_file)
  unzip(zipfile = tmp_file, exdir = tmp_dir)
  fpath <- paste(tmp_dir, sprintf("districtShapes/districts114.shp",cong), sep = "/")
  st_read(fpath)
}

# load 114th congress
cd114 <- get_congress_map(114)

# divide by district
cd114$DISTRICT <- as.numeric(cd114$DISTRICT)
cd114 <- cd114 %>% left_join(D_2018, by=c("DISTRICT", "STATENAME"))
cd114RS <- cd114 %>% left_join(D_2018_RS, by=c("DISTRICT", "STATENAME"))
cd114RSC <- cd114 %>% left_join(D_2018_R_com, by=c("DISTRICT", "STATENAME"))

districts_simp <- rmapshaper::ms_simplify(cd114, keep = 0.01)
districts_simp_RS <- rmapshaper::ms_simplify(cd114RS, keep = 0.01)
districts_simp_RS_C <- rmapshaper::ms_simplify(cd114RSC, keep = 0.01)
```

```{r, echo = FALSE}
# Map(1)
ggplot() +
  geom_sf(data=districts_simp,aes(fill= D_votemargin_cd), 
          inherit.aes=FALSE,alpha=0.9) +
  scale_fill_gradient(low = "red", high = "blue", limits=c(-100,100)) +
  coord_sf(xlim = c(-172.27, -66.57), ylim = c(18.55, 71.23), expand = FALSE) +
  theme_void() + 
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())
```
This first map visualizes actual voteshare at the district level in 2018, based on the Democrat vote margin percentage. The map holds many districts that are blue and those that lean towards blue. It means that there is a larger voteshare for Democrats (which is in their favor) at the district level. 

```{r, echo = FALSE}
# Map(2)
ggplot() +
  geom_sf(data=districts_simp_RS,aes(fill= cpr_num), 
          inherit.aes=FALSE,alpha=0.9) +
  scale_fill_gradient(low = "blue", high = "red", limits=c(1,7)) +
  coord_sf(xlim = c(-172.27, -66.57), ylim = c(18.55, 71.23), expand = FALSE) +
  theme_void() + 
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())
```
This map visualizes expert predictions based on the Cook Political Report data at the district-level in 2018. There seems to be 1) a larger proportion of secure red districts and 2) stronger blue districts, especially along the West Coast. However, we must assess the first takeaway with a grain of salt: the overreporting of secure Republican districts may seem more than it actually is because the visualization of the data can mislead with the bigger areas of districts in rural areas. 

Overall, the predictions are more extreme in both directions (in that there are more districts that are safe Democrat or safe Republican) than the actual voteshare. As Enos and Hersh show in their 2015 paper "Campaign Perceptions of Electoral Closeness: Uncertainty, Fear and Over-Confidence", political campaign operatives tend to be overconfident in their candidates' performance, skewing the perception of the election's closeness. 

Recent elections have only been stronger in support that polling may not be the most accurate tool in election forecasting. In his 2021 study "Failure and Success in Political Polling and Election Forecasting", Andrew Gelman explains that the polls in both recent presidential elections with both Clinton and Biden are examples of the overstatement of Democratic strength, a pattern also seen in recent congressional elections. Through Gelman's experience studying public opinion, he attributes the large proportion of swing in polls to a type of polling bias called "differential nonresponse", in which supporters of candidates are more vocal in surveys when their candidate does well. This phenomenon, accompanied by high correlations between each party's share of support in each poll and the percentage of partisans among respondents, only highlights the growing variable of partisanship. Gelman finds that there is a historical overestimate of Democrat performance due to factors such as this differential nonresponse and differential turnout. However, the 2018 elections were a place for polls to redeem their quality. 

```{r, echo = FALSE}
# Map(3)
ggplot() +
  geom_sf(data=districts_simp_RS_C,aes(fill= Accuracy), 
          inherit.aes=FALSE,alpha=0.9) +
  scale_fill_gradient(low = "pink", high = "yellow", limits=c(-2,2)) +
  coord_sf(xlim = c(-172.27, -66.57), ylim = c(18.55, 71.23), expand = FALSE) +
  theme_void() + 
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())
```
The third map shows exactly this result, with many polls yielding a difference of 0 in accuracy between the actual voteshare and the expert predictions. This meant that the 2018 predictions held consistent accuracy and if there were differences between the first two maps, they were small. The NYT article "What the Polls Got Right This Year, and Where They Went Wrong" found that while the 2018 expert predictions were a significant increase in accuracy compared to the 2016 elections, the polls underestimated Democrats in several states where they also underestimated Democrats in 2016 like California, New York, and Nevada. "Our polls did not overestimate Democrats in the less educated states and districts of the East, where one might expect the phenomenon to show up, though they did underestimate Democrats in California and the Southwest."  The 2018 expert predictions yielded many precise results. While there was error, it was small and mostly negative, underestimating Democrats’ performance and overestimating Republicans’. Examples can be found in Minnesota’s 7th district, which underestimated Republicans and Nevada’s 4th congressional district, which underestimated the Democrats. This type of error, which was also found in Florida, was to be expected, especially looking at the patterns from previous years. While recent polls from 2016 and 2020 give more and more reason to distrust polls, 2018 was a good year for expert accuracy and optimizing probabilistic forecasting tools to understand how the American public feels about upcoming elections. 

```{r, echo = FALSE}
library(readr)
EE_data <- read_csv("data/Election_Economy_R1.csv")

#=====================================================================
HVS_data <- read.csv("data/house party vote share by district 1948-2020_R1.csv")

lm_econ_D1 <- lm(D_seats ~ GDP_Growth_Pct+US_CPI+US_Unemployment_Rate, data = EE_data)
summary(lm_econ_D1)

lm_econ_D2 <- lm(D_seats ~ D_majorvote_pct_lag+GDP_Growth_Pct+US_CPI+US_Unemployment_Rate, data = EE_data)
summary(lm_econ_D2)

lm_econ_D3 <- lm(D_seats ~ D_majorvote_pct_lag+GDP_Growth_Pct+US_CPI, data = EE_data)
summary(lm_econ_D3)

lm_econ_D4 <- lm(D_seats ~ D_majorvote_pct_lag+GDP_Growth_Pct+US_CPI+Pres_R, data = EE_data)
summary(lm_econ_D4)
```

```{r, echo = FALSE}
##lm_incumb_D1 <- lm(DemVotes ~ incumbent_party+open_seat, data = HVS_data)

# GDP

lm_econ1 <- lm(H_incumbent_party_majorvote_pct ~ GDP_Growth_Pct,
data = EE_data) 

summary(lm_econ1)

plot(EE_data$year, EE_data$H_incumbent_party_majorvote_pct,
type="l", main="true Y (line), predicted Y (dot) for each year")
points(EE_data$year, predict(lm_econ1, EE_data))

mse_m1 <- mean((lm_econ1$model$H_incumbent_party_majorvote_pct - lm_econ1$fitted.values)^2)

sqrt(mse_m1)

summary(lm_econ1)$r.squared
```

```{r, echo = FALSE}
lm_econ2 <- lm(H_incumbent_party_majorvote_pct ~ US_Unemployment_Rate,
data = EE_data) 

summary(lm_econ2)

# Unemployment Rate
plot(EE_data$year, EE_data$H_incumbent_party_majorvote_pct,
type="l", main="true Y (line), predicted Y (dot) for each year")
points(EE_data$year, predict(lm_econ2, EE_data))
```


```{r, echo = FALSE}
# Unemployment Rate
mse_m2 <- mean((lm_econ2$model$H_incumbent_party_majorvote_pct - lm_econ2$fitted.values)^2)

sqrt(mse_m2)

summary(lm_econ2)$r.squared
```

```{r, echo = FALSE}
lm_econ3 <- lm(H_incumbent_party_majorvote_pct ~ US_CPI,
data = EE_data) 

summary(lm_econ3)

# US_CPI
plot(EE_data$year, EE_data$H_incumbent_party_majorvote_pct,
type="l",
main="true Y (line), predicted Y (dot) for each year")
points(EE_data$year, predict(lm_econ3, EE_data))
```

```{r, echo = FALSE}
# CPI
mse_m3 <- mean((lm_econ3$model$H_incumbent_party_majorvote_pct - lm_econ3$fitted.values)^2)

sqrt(mse_m3)

summary(lm_econ3)$r.squared
```
## Conclusion on Updated Model:
lm_1: y = pop vote = -0.2397(GDP Growth Pct) + 52.7003
lm_2: y = pop vote = 0.1875(US Unemployment Rate) + 48.5044
lm_3: y = pop vote = -0.017690(US_CPI) + 53.7787
note: For each model, the estimated coefficients for the independent variable indicates a marginal effect on the dependent variable, which is popular vote for the incumbent. Ex: For Model 1, a 1 unit increase (1% increase in annual GDP Growth Percentage) yields a decrease of 0.2397% in House Incumbent Party Majority Vote Percentage. For Model 2, a 1 unit increase (1% increase in the U.S. Unemployment Rate) yields an increase of 0.1875% in House Incumbent Party Majority Vote Percentage. For Model 3, a 1 unit increase (1% increase in the U.S. Consumer Price Index) yields a decrease of 0.01769% in House Incumbent Party Majority Vote Percentage. Below, I assess the accuracy of each of these models. 

The GDP Growth Percentage seems to hold the lowest predictive power in estimating the marginal effect on the popular vote. With a relatively high mean-squared error of about 3.2433 and a low R squared value of 0.044, Model 1  has the lowest accuracy in the linear regression model predicting popular votes. Five Thirty-Eight found that "There is definitely a relationship between G.D.P. and election results. But, it isn’t a perfect one. Overall the r-squared for G.D.P. is .33 in elections since 1948. That is, about 33 percent of election results are explained by G.D.P., leaving about two-thirds of the results unexplained."

The U.S. Unemployment Rate is in the middle with its predictive power with a mean-squared error of about 3.1975 and a R squared value of 0.0708. While there exists literature on the relationship between unemployment rate and approval rates of the President and Congress, there is a lack of clear information on the chances of re-election. Five Thirty-Eight ambiguously concluded that the data is not strong enough to prove a relationship between unemployment rate and popular vote, but "it is also not strong enough to disprove a relationship." 

CPI is a natural measure of inflation and when it goes up, it yields a decrease of 0.01769%, giving a conclusive effect. Out of all 3 models, the CPI factor has the smallest mean-squared error of about 3.0029, indicating that this is the best performing model and holds the highest predictive power out of all 3 in estimating the House Incumbent Party Majority Vote Percentage. Another reason this model may be the closest in accuracy of prediction is that it is the only one that is statistically significant. As the R squared value gets higher, it indicates how much variation of y values in the sample is captured by the fitted model's predicted values, and how much can be explained by the estimation models. CPI has the highest R squared value of 0.1805. Even though about 82% of the variation is not captured, it is still the best predictive model we have on hand. Through Model 3, based on CPI, we find that if the CPI continuously increased over time, it is natural to see the continuously decreasing popular vote (predicted value in dots). The Pew Research Center found that inflation is a key factor in their voting decisions, and in the context of Democrats controlling the House and the presidency, personal financial ratings in response to inflation lean more negative, especially for Republicans. Overall, Democrat views of the economy, while negative, are still more positive than Republicans'. "The Electoral Impact of Unexpected Inflation and Economic Growth" by Harvey Palmer and Guy Whitten reveals through empirical analysis stronger electoral effects for unexpected inflation and growth, serving as reliable indicators of government competence to voters and therefore lending itself to higher or lower approval rates/incumbent popularity. Of course, there are many more economic factors of wellbeing that are more well-favored by political scientists, such as growth in real disposable income, but for the time being, CPI is most accurate. 