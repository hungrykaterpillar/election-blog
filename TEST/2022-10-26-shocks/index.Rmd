---
title: Shocks
author: Kate Lim-Shim
date: '2022-10-26'
slug: []
categories: []
tags: []
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
install.packages("dotenv")
install.packages("jsonlite")
library(dotenv)
library(jsonlite)
library(tidyverse)
library(lubridate)
```

```{r, include = FALSE}
# load up hidden api key
##article_api <- Sys.getenv("ARTICLE_API")
article_api <- "0p3IEUVHLdviUXt6BODkPbKF0f9aU3YV"

  #"zbNGtPzlJflHASLOR1jGJDAngZjfCuNK"
#semantic_api <- Sys.getenv("SEMANTIC_API")

# set base url
base_url_art <- "http://api.nytimes.com/svc/search/v2/articlesearch.json?fq="
#base_url_sem <- "http://api.nytimes.com/svc/semantic/v2/concept/name"w

# set parameters
term <- "Uvalde"
##fq <- "&fq=glocation='New York City'"
facet_field <- "day_of_week"
facet <- "true"
begin_date <- "20220101"
end_date <- "20221025"
complete_url <- "https://api.nytimes.com/svc/search/v2/articlesearch.json?fq=Uvalde&facet_field=day_of_week&facet=true&begin_date=20220101&end_date=20221015&api-key=0p3IEUVHLdviUXt6BODkPbKF0f9aU3YV" #"https://api.nytimes.com/svc/search/v2/articlesearch.json?fq=dobbs&facet_field=day_of_week&facet=true&begin_date=20220101&end_date=20221015&api-key=zbNGtPzlJflHASLOR1jGJDAngZjfCuNK"
```

```{r, include = FALSE}
complete_url2 <-paste0(base_url_art,fq =term,"&facet_field=",facet_field,"&facet=",facet,"&begin_date=",begin_date,"&end_date=",end_date,"&api-key=",article_api,sep = "")

##complete_url <- paste0(base_url_art,term,fq,"&begin_date=",begin_date,"&end_date=",end_date,"facet_filter=true&api-key=",article_api,sep = "")

# import dataset to R
sus <- fromJSON(complete_url2) 

# view how many hits
sus$response$meta$hits

hits <- sus$response$meta$hits
cat("There were ",hits," hits for the search term Uvalde during 2022 to date",sep = "")

max_pages <- round((hits / 10) - 1)

# store all pages in list
#pages <- list()
#for(i in 0:max_pages){
    #sus_df <- fromJSON(paste0(complete_url2, "&page=", i),
    #flatten = TRUE) %>% 
    #data.frame() 
  #message("Retrieving page ", i)
  #pages[[i+1]] <- sus_df
  #Sys.sleep(6)
#}
```

```{r, include = FALSE}
# trying again - WORKS!!!
sus0 <- fromJSON(paste0(complete_url2, "&page=0"), flatten = TRUE)
nrow(sus0$response$docs)
sus1 <- fromJSON(paste0(complete_url2, "&page=1"), flatten = TRUE)
nrow(sus1$response$docs)
sus2 <- fromJSON(paste0(complete_url2, "&page=2"), flatten = TRUE)
nrow(sus2$response$docs)

organizations <- rbind_pages(
  list(sus0$response$docs, sus1$response$docs, sus2$response$docs)
)
nrow(organizations)

pages <- list()
Sys.sleep(1) 
for(i in 0:42){
  mydata <- fromJSON(paste0(complete_url2, "&page=", i))
  message("Retrieving page ", i)
  pages[[i+1]] <- mydata$response$docs
  Sys.sleep(6) 
}
```

```{r, include = FALSE}
#combine all into one
organizations <- rbind_pages(pages)

#check output
nrow(organizations)

colnames(organizations)


# trying with hits
sus0 <- fromJSON(paste0(complete_url2, "&page=0"), flatten = TRUE)
nrow(sus0$response$docs)
sus1 <- fromJSON(paste0(complete_url2, "&page=1"), flatten = TRUE)
nrow(sus1$response$docs)
sus2 <- fromJSON(paste0(complete_url2, "&page=2"), flatten = TRUE)
nrow(sus2$response$docs)

organizations <- rbind_pages(
  list(sus0$response$docs, sus1$response$docs, sus2$response$docs)
)
nrow(organizations)

pages <- list()
Sys.sleep(1) 
for(i in 0:42){
  mydata <- fromJSON(paste0(complete_url2, "&page=", i)) 
  message("Retrieving page ", i)
  pages[[i+1]] <- mydata$response$docs
  Sys.sleep(6) 
}
```

```{r}
#####simply do not run this block, no worries!
#pages <- as.data.frame(pages)
#do.call(rbind.data.frame, pages)
#library (plyr)
#rbind.fill(pages)
#pages <- ldply(pages, data.frame)
#data.frame(t(sapply(pages,c)))
```

```{r, include = FALSE}
#combine all into one
mydata <- rbind_pages(pages)

#check output
nrow(mydata)

# save df
saveRDS(mydata, file = "Russia_2022.RDS")

# reload
mydata <- readRDS("Russia_2022.RDS")

# check colnames
colnames(mydata)
```

```{r, echo = FALSE}
# visualization by month
library(dplyr)
mydata %>% 
  group_by(month = month(pub_date, label = T)) %>% 
  dplyr::summarize(count = n()) %>% 
  ggplot(aes(month, count, group = 1, color = count)) +
    geom_line() +
    labs(y = "Article Count", x = "",
         title = "NYT Articles mentioning Uvalde in 2022",
         color = "")
```

```{r, echo = FALSE}
# visualization by day
mydata %>% 
  group_by(month_day = paste0(month(pub_date, label = T),
           day = day(pub_date))) %>% 
  dplyr::summarize(count = n()) %>% 
  ggplot(aes(month_day, count, group = 1, color = count)) +
    geom_line() +
    labs(y = "Article Count", x = "",
         title = "NYT Articles mentioning Uvalde in 2022",
         color = "")
```

```{r, include = FALSE}
# how about visualization by week
# extract raw date
mydata <- mydata %>% 
  mutate(publ_date = substr(pub_date, 1, 10))
head(mydata$publ_date)

# mutate week variable
mydata <- mydata %>% 
  mutate(week = strftime(publ_date, format = "%V"))
head(mydata$week)
```

```{r, echo = FALSE}
# plot
mydata %>% 
  group_by(week) %>% 
  dplyr::summarize(count = n()) %>% 
  ggplot(aes(week, count, group = 1, color = count)) +
    geom_line() +
    labs(y = "Article Count", x = "Week",
         title = "NYT Articles mentioning Uvalde in 2022",
         color = "") + # now add line for when Uvalde was first mentioned
      geom_segment(x=("21"), xend=("21"),y=0,yend=180, lty=2, color="purple", alpha=0.4) + annotate("text", x=("22"), y=150, label="Uvalde Shooting", size=3)  # now add line for when decision was actually made
```
I chose the Uvalde, Texas school shooting as a potential political shock, because of the nationwide politicization of gun violence in general and this event specifically. Here, it is shown that The Uvalde Shooting at 21 weeks in 2022 (the event itself occurred on May 24th, 2022) spiked the number of articles written containing the keyword "Uvalde" from nearly 0 articles the week before to nearly 130 articles the week of the shooting. Although the article count has steadily decreased to a manageable number, it still is above 0 and there were still many articles written 8 weeks after the shooting, showing the significance of the event on national news and media. 

```{r, include = FALSE}
library(dplyr)

# now compare this to generic ballot
X538_generic_ballot_averages_2018_2022 <- read_csv("538_generic_ballot_averages_2018-2022.csv")
gb <- X538_generic_ballot_averages_2018_2022

# convert dat
gb <- gb %>%
  mutate(date_ = mdy(date)) %>%
  mutate(year = substr(date_, 1, 4)) %>%
  filter(year == 2022) %>%
  mutate(week = strftime(date_, format = "%V")) # Jan 1 looks weird 

# get avg by party and week
dem <- gb %>%
  filter(candidate == 'Democrats')
x <- plyr::ddply(dem, .(week), function(z) mean(z$pct_estimate))
x$candidate <- c('Democrats')
x$avg_dem <- x$V1
x <- x %>%
  select(-V1)
x$avg_dem <-  round(x$avg_dem , digits = 1)


rep <- gb %>%
  filter(candidate == 'Republicans')
y <- ddply(rep, .(week), function(z) mean(z$pct_estimate))
y$candidate <- c('Republicans')
y$avg_rep <- y$V1
y <- y %>%
  select(-V1) 
y$avg_rep <-  round(y$avg_rep, digits = 1)
```

```{r, include = FALSE}
#put all data frames into list
df_list <- list(gb, x, y)      

#merge all data frames together
polls_df <- df_list %>% reduce(full_join, by=c("candidate", "week"))

# remove NAs
polls_df[] <-  t(apply(polls_df, 1, function(x) c(x[!is.na(x)], x[is.na(x)])))

polls_df <- polls_df %>%
  select(-avg_rep) 

polls_df$avg_support <- polls_df$avg_dem

polls_df <- polls_df %>%
  select(-avg_dem) 

# keep only unique dates
polls_df <- polls_df %>%
  distinct(cycle, week, date_, avg_support, candidate) %>%
  filter(week != 52)
```

```{r, echo = FALSE}
# visualize polls
polls_df %>%
  #group_by(candidate == 'Democrats') %>%
  #mutate(date_ = as.Date(date_)) %>%
  ggplot(aes(x = week, y = avg_support,
             colour = candidate)) +
  geom_line(aes(group=candidate), size = 0.3) + geom_point(size = 0.3) +
    #scale_x_date(date_labels = "%b, %Y") +
  ylab("generic ballot support") + xlab("week") +
    theme_classic() + 
  # now add line for when Uvalde Shooting happend (May 24, 21st week)
      geom_segment(x=("21"), xend=("21"),y=0,yend=33, lty=2, color="purple", alpha=0.4) +
      annotate("text", x=("21"), y=31, label="Uvalde Shooting", size=2) 

``` 
After understanding how significant the Uvalde shooting was in national conversation (shown through the NYT article count), it would be helpful to see how this "shock" affected Democrat and Republican ballot support, seeing if the shock was political in nature. Prior to the shooting itself, generic ballot support for Republicans was already decreasing from a peak. After the shooting, the decreasing trend continued so it is difficult to say if it is exactly the Uvalde shooting that was an isolated factor in decreasing support. The Democrat ballot support dipped right after the shooting (which could make sense in that voters could have felt disappointed in the lack of gun control policies), but about a month after the shooting when the support hit a new low, Democrat support started to steadily increase. This effect has been lasting for more than 12 weeks. While there could be other factors/events such as the Dobbs Supreme Court Decision or President Biden's pardoning of those in jail because of marijuana possession, it is undeniable that after the shooting, the Democrat ballot support increased. This result affects my predictions in that I expect many more events that are political and non-political to have meaningful and logical effects on my model. However, I also predict that other events that may not be political in nature may have effects that do not make sense, such as the 24th week (mid-June) of 2022. The Sheep Fire burned through California during this week, among other occurrences unrelated to ballot support. How could one isolate certain events in predicting their effects on national seat share? 

##Updated Prediction Model
```{r}
# read csv file and create an object, h
Exp_Pred <- read.csv("R_1024/Expert_Prediction_cleaned.csv")
Ads_Cost <- read.csv("R_1024/Ads_Cost_2012_2018.csv")
CVAP <- read.csv("R_1024/cvap_district_2012-2020_clean.csv")
Vote_Inc <- read.csv("R_1024/incumb_dist_1948-2020 (3).csv")

# loading required packages
library(tidyverse)
```

```{r}
Exp_Pred_2012_2020 <- Exp_Pred %>%
  select(year, state, district_num, avg_rating, Close_E_D, LLS_D, LLS_R, St_AVG_R) %>%
  group_by(year, state, district_num) %>%
  rename(DISTRICT = district_num, STATENAME = state)

Ads_Cost_2012_2018 <- Ads_Cost %>%
  select(st_cd_fips, STATENAME, DISTRICT, year, est_cost_sum) %>%
  group_by(year, STATENAME, DISTRICT) %>%
  rename(DISTRICT = DISTRICT, STATENAME = STATENAME)

CVAP_2012_2020 <- CVAP %>%
  select(cd, state, cvap, year) %>%
  group_by(year, state, cd) %>%
  rename(DISTRICT = cd, STATENAME = state)

Vote_Inc_1948_2020 <- Vote_Inc %>%
  select(year, state, district_num, RepVotes, DemVotes,RepVotesMajorPercent, DemVotesMajorPercent, Incumbent_R, Incumbent_D, Open_seat) %>%
  group_by(year, state, district_num) %>%
  rename(DISTRICT = district_num, STATENAME = state)
````

```{r}
ExpP_LJ_CVAP_2012_2020 <- Exp_Pred_2012_2020 %>% left_join(CVAP_2012_2020, by=c("year", "DISTRICT", "STATENAME"))

Final_Dataset_2012_2020 <- ExpP_LJ_CVAP_2012_2020 %>% left_join(Vote_Inc_1948_2020, by=c("year", "DISTRICT", "STATENAME")) 

Final_2012_2020_D <- Final_Dataset_2012_2020 %>%
  select(year, STATENAME, DISTRICT, avg_rating, Close_E_D, LLS_R, LLS_D, St_AVG_R, cvap, RepVotes, DemVotes, RepVotesMajorPercent, DemVotesMajorPercent, Incumbent_R, Incumbent_D, Open_seat) %>%
  mutate(voterTR = ((RepVotes)+(DemVotes))/(cvap)) %>%
  rename(DISTRICT = DISTRICT, STATENAME = STATENAME)

##write.csv(Final_2012_2018_D, "Final_2012_2020_D.csv")
```

```{r}
############
library(readr)
Final_2012_2020_DF <- read_csv("~/Downloads/R_1024/Final_2012_2020_DF.csv")

Final_2012_2018_DF <- Final_2012_2020_DF %>% left_join(Ads_Cost_2012_2018, by=c("year", "DISTRICT", "STATENAME"))

EE_data_R1 <- read.csv("~/Downloads/R_1024/Election_Economy_R1.csv")
Final_2012_2018_DF_ME_R1 <- EE_data_R1 %>% left_join(Final_2012_2018_DF, by=c("year"))
write.csv(Final_2012_2018_DF_ME_R1, "~/Downloads/R_1024/Final_2012_2018_DF_ME_R1.csv")
##### interpretation: XXXXXX
##==================================================
lm_DVsh_M1 <- lm (DemVotesMajorPercent ~ Close_E_D+LLS_D+Pres_D+GDP_Growth_Pct+US_CPI+US_Unemployment.Rate, data=Final_2012_2018_DF_ME_R1)
summary(lm_DVsh_M1)
##### interpretation: XXXXXX
##==================================================
```

```{r}
Demog_0920 <- read.csv("demographic_2009_2020.csv")
Demog_0920 <- Demog_0920 %>% mutate_at(c('district'), as.numeric)

Demog_0920_R <- Demog_0920 %>%
  rename(DISTRICT = district, STATENAME = state)

Final_Dataset_2012_2020_ME_R2 <- Final_2012_2018_DF_ME_R1 %>% left_join(Demog_0920_R, by=c("year", "DISTRICT", "STATENAME")) 
```

```{r}
##==================================================
lm_DVsh_M2 <- lm (DemVotesMajorPercent ~ Close_E_D+LLS_D+Pres_D+GDP_Growth_Pct+US_CPI+US_Unemployment.Rate+female+X20_29+white, data=Final_Dataset_2012_2020_ME_R2)
summary(lm_DVsh_M2)
### interpretation XXXXXXX
#### Adj R-square got improved to 0.7069 and F-statistic shows that the independent variables are jointly significant in estimating the DemVotesMajorPercent
###### female: 1% (0.01) increase in female population increased the democrat major vote share (DemVotesMajorPercent) by 0.4396%
###### X20_29: 1% (0.01) increase in population in 20s (20-29) increased the democrat major vote share (DemVotesMajorPercent) by 0.1975%
###### white: 1% (0.01) increase in white (not Hispanic) population decreased the democrat major vote share (DemVotesMajorPercent) by 0.02473%

lm_DVsh_M3 <- lm (DemVotesMajorPercent ~ Close_E_D+LLS_D+Pres_D+GDP_Growth_Pct+US_CPI+US_Unemployment.Rate+female+X20_29+X65.+white, data=Final_Dataset_2012_2020_ME_R2)
summary(lm_DVsh_M3)
### interpretation XXXXXXX
#### Adj R-square got improved to 0.7080 and F-statistic shows that the independent variables are jointly significant in estimating the DemVotesMajorPercent
###### female: 1% (0.01) increase in female population increased the democrat major vote share (DemVotesMajorPercent) by 0.4286%
###### X20_29: 1% (0.01) increase in population in 20s (20-29) increased the democrat major vote share (DemVotesMajorPercent) by 0.1408% (but significant only at 10%-level, not at 5%)
###### X65.: 1% (0.01) increase in elderly population 65 yrs and older (>=65) decreased the democrat major vote share (DemVotesMajorPercent) by 0.0922% (but significant only at 10%-level, not at 5%)
###### white: 1% (0.01) increase in white (not Hispanic) population decreased the democrat major vote share (DemVotesMajorPercent) by 0.02081%
##==================================================
```
Compared to last week's model, the Adjusted R-squared was improved to 0.7069 in the first model which created a linear regression based on using the variables of close election (dummy variable), lean/likely/strong Democrats (dummy), Democratic President (dummy), GDP Growth Percentage, U.S. Consumer Price Index (CPI), U.S. Unemployment Rate, female or not (dummy), population belonging to ages 20-29, and White population. These were all used to predict the DemVotesMajorPercent output, which was the national win share for Democrats. 

In this model, the F-statistic value shows that the independent variables are jointly significant in estimating the DemVotesMajorPercent. The Close Election variable, which was significant at 0.1%, had a positive effect on the DemVotesMajorPercent with a 1% increase in Close Election increasing the DemVotesMajorPercent by 12.03%. A 1% increase in Lean, Likely, and Strong Democrats was significant at 0.1% and increased the Democrat vote share by 5.97%. A 1% increase in the Democrat President (significant at 0.1%) decreased the Democrat vote share by 8.69%. A 1% increase in the GDP Growth Percentage (significant at 0.1%) increased the Democrat vote share by 6.83%. A 1% increase in the U.S. CPI (significant at 0.1%) decreased the Democrat vote share by 0.36%. A 1% increase in the U.S. Unemployment Rate (significant at 0.1%) increased the Democrat vote share by 0.47%. A 0.01% increase in the female population (significant at 5%) increased the Democrat vote share by 0.4396%. A 1% increase in the population aged 20-29 (significant at 1%) increased the vote share by 19.75%. A 1% increase in the White, non-Hispanic population (significant at 1%) decreased the Democrat vote share by 0.0247%. 

To improve the predictive power of my model, I added one more variable: elderly population aged 65 or older. The Close Election, Lean, Likely, Strong Democrats, Democrat President, and other economic indicators of GDP Growth Percentage, U.S. CPI, and U.S. Unemployment Rate were all similar in their effects on the DemVotesMajorPercent variable. Overall, the adjusted R-squared was slightly improved to 0.7080 and the F-Statistic showed that the independent variables are all jointly significant in estimating the DemVotesMajorPercent. A 1% increase in the female population, significant at 5%, increased the Democrat Major Vote Share outcome by 0.4286%. A 1% increase in the population in their 20s (signficant at 10%) increased the Democrat vote share by 0.1408%. A 1% increase in the elderly population 65 years and older (significant at 10%) decreased the Democrat vote share by 0.0922%. A 1% increase in the White, non-Hispanic population (significant at 5%) decreased the Democrat vote share by 0.02081%. While the overall R squared increased, some variables only became significant at higher p-values, which could decrease the quality of their explanatory power.